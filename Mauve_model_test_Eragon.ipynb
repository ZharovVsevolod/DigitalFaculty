{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ранагон\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils.poetry import *\n",
    "from utils.base import *\n",
    "from utils.transformer_tools import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import youtokentome as yttm\n",
    "import mauve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка изначального файла, кодировка, уничтожение пустых строк\n",
    "\n",
    "with open(\"datasets/Eragon/Eragon_4_cut.txt\", encoding=\"utf-8\") as input_file:\n",
    "    horus = input_file.read().split('\\n')\n",
    "    horus = [value for value in horus if value != \"\"]\n",
    "    # horus = [value.replace(u'\\xa0', u' ') for value in horus]\n",
    "\n",
    "with open(\"datasets/Eragon/Eragon4mauve.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in horus:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "ugh. Two of the soldiers fell as Angela buried the wool combs in their sides, driving the tines right through their hauberks. The herbalist was more than a foot shorter than some of the men, but she showed no sign of fear as she bounded among them. To the contrary, she was the picture of ferocity, w\n"
     ]
    }
   ],
   "source": [
    "for_mauve_test = load_chunks(\"./datasets/Eragon/Eragon4mauve.txt\", chunk_size=300)\n",
    "\n",
    "\n",
    "print(len(for_mauve_test))\n",
    "print(for_mauve_test[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPE_MODEL_FILENAME = 'models/tokens/eragon_bpe_1000.yttm'\n",
    "tokenizer = yttm.BPE(BPE_MODEL_FILENAME)\n",
    "\n",
    "G_model = Language_Model(\n",
    "    vocab_size = tokenizer.vocab_size(),\n",
    "    embedding_size = 256,\n",
    "    backbone = Transformer_Encoder(\n",
    "        nn.TransformerEncoderLayer(\n",
    "            d_model = 256,\n",
    "            nhead = 16,\n",
    "            dim_feedforward = 512,\n",
    "            dropout = 0.1\n",
    "        ),\n",
    "        num_layers=5\n",
    "    ),\n",
    "    emb_dropout = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model_gan = Language_Model(\n",
    "    vocab_size = tokenizer.vocab_size(),\n",
    "    embedding_size = 256,\n",
    "    backbone = Transformer_Encoder(\n",
    "        nn.TransformerEncoderLayer(\n",
    "            d_model = 256,\n",
    "            nhead = 16,\n",
    "            dim_feedforward = 512,\n",
    "            dropout = 0.1\n",
    "        ),\n",
    "        num_layers=5\n",
    "    ),\n",
    "    emb_dropout = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model_gan.load_state_dict(torch.load('./models/GAN/Eragon/model_G.pth'))\n",
    "G_model_gan.cuda()\n",
    "\n",
    "G_model.load_state_dict(torch.load('./models/Lord/Eragon/Lord.pth'))\n",
    "G_model.cuda()\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_generator = Gen_method(G_model, tokenizer)\n",
    "fake_texts = []\n",
    "\n",
    "loop_generator_gan = Gen_method(G_model_gan, tokenizer)\n",
    "fake_texts_gan = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151/151 [05:02<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(for_mauve_test))):\n",
    "    fake_texts.append(loop_generator(for_mauve_test[i], N_cut=15, need_reweight=True, temper=0.3, alpha=0.15)[0])\n",
    "    fake_texts_gan.append(loop_generator_gan(for_mauve_test[i], N_cut=15, need_reweight=True, temper=0.3, alpha=0.15)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eragon grabbed himself and said, “Is it?” “Of course,” said Brom. “Of course, I would have a choice.” “Yes,” said Brom. “\n",
      "Eragon grabbed Zar’roc, and held the sword onto his knees, then clung his hands over the sword. The sword pointed at his neck, and he he\n"
     ]
    }
   ],
   "source": [
    "print(fake_texts[4])\n",
    "print(fake_texts_gan[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_texts_to_file(fake_texts_gan, \"./datasets/Eragon/Eragon_fake_rankgen.txt\")\n",
    "save_texts_to_file(fake_texts, \"./datasets/Eragon/Eragon_fake_rankgen_old.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing p: 100%|██████████| 151/151 [02:44<00:00,  1.09s/it]\n",
      "Featurizing q: 100%|██████████| 155/155 [01:29<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17324015105647228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing p: 100%|██████████| 151/151 [02:44<00:00,  1.09s/it]\n",
      "Featurizing q: 100%|██████████| 155/155 [01:32<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11811598094379097\n"
     ]
    }
   ],
   "source": [
    "out_old = mauve.compute_mauve(p_text=for_mauve_test, q_text=fake_texts)\n",
    "print(out_old.mauve)\n",
    "\n",
    "out_gan = mauve.compute_mauve(p_text=for_mauve_test, q_text=fake_texts_gan)\n",
    "print(out_gan.mauve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
